import streamlit as st
import google.generativeai as genai
import sqlite3
import uuid
from PIL import Image
import io

# --- CONFIGURARE PAGINÄ‚ ---
st.set_page_config(
    page_title="Asistent Artizan TradiÈ›ional",
    page_icon="ğŸ¨",
    layout="centered"
)

# --- CSS PENTRU STILIZARE ---
st.markdown("""
<style>
    .stChatMessage {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 10px;
    }
    .stButton button {
        background-color: #ff4b4b;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# --- CONFIGURARE GEMINI API ---
# Se preia cheia din Streamlit Secrets
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEYS"])
except:
    st.error("Te rog configureazÄƒ GOOGLE_API_KEYS Ã®n Streamlit Secrets!")
    st.stop()

# Modelul Gemini (Flash este rapid È™i multimodal)
model = genai.GenerativeModel('gemini-1.5-flash')

# InstrucÈ›iuni de sistem (Persona AI-ului)
SYSTEM_PROMPT = """
EÈ™ti un expert Ã®n artÄƒ popularÄƒ romÃ¢neascÄƒ, tradiÈ›ii, folclor È™i marketing pentru produse handmade.
Rolul tÄƒu este sÄƒ ajuÈ›i un artist sÄƒ creeze produse autentice (mÄƒrÈ›iÈ™oare, cadouri de CrÄƒciun, PaÈ™te).
1. AnalizeazÄƒ pozele Ã®ncÄƒrcate din punct de vedere estetic È™i al materialelor.
2. SugereazÄƒ Ã®mbunÄƒtÄƒÈ›iri cromatice sau materiale naturale (lemn, lÃ¢nÄƒ, lut) specifice sezonului.
3. CreeazÄƒ o poveste lungÄƒ, emoÈ›ionantÄƒ, cu iz arhaic romÃ¢nesc pentru fiecare produs, pe care artistul sÄƒ o punÄƒ pe etichetÄƒ sau pe social media.
Tonul trebuie sÄƒ fie cald, Ã®ncurajator È™i respectuos faÈ›Äƒ de tradiÈ›ie.
"""

# --- GESTIONARE BAZÄ‚ DE DATE (SQLite) ---
def init_db():
    conn = sqlite3.connect('chat_history.db')
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            session_id TEXT,
            role TEXT,
            content TEXT,
            has_image BOOLEAN
        )
    ''')
    conn.commit()
    conn.close()

def save_message(session_id, role, content, has_image=False):
    conn = sqlite3.connect('chat_history.db')
    c = conn.cursor()
    c.execute('INSERT INTO messages (session_id, role, content, has_image) VALUES (?, ?, ?, ?)',
              (session_id, role, content, has_image))
    conn.commit()
    conn.close()

def get_history(session_id):
    conn = sqlite3.connect('chat_history.db')
    c = conn.cursor()
    c.execute('SELECT role, content, has_image FROM messages WHERE session_id = ? ORDER BY id', (session_id,))
    rows = c.fetchall()
    conn.close()
    return rows

def clear_session_history(session_id):
    conn = sqlite3.connect('chat_history.db')
    c = conn.cursor()
    c.execute('DELETE FROM messages WHERE session_id = ?', (session_id,))
    conn.commit()
    conn.close()

# IniÈ›ializÄƒm baza de date la pornire
init_db()

# --- GESTIONARE SESIUNE (URL Query Params) ---
# VerificÄƒm dacÄƒ existÄƒ un ID Ã®n URL
query_params = st.query_params
if "session_id" not in query_params:
    # GenerÄƒm un ID nou È™i Ã®l punem Ã®n URL
    new_id = str(uuid.uuid4())
    st.query_params["session_id"] = new_id
    session_id = new_id
else:
    # Folosim ID-ul existent
    session_id = query_params["session_id"]

# --- SIDEBAR ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2913/2913465.png", width=100)
    st.title("Atelier Virtual")
    st.info(f"ID Sesiune: {session_id[:8]}...")
    st.markdown("Acest ID pÄƒstreazÄƒ conversaÈ›ia chiar dacÄƒ Ã®nchizi pagina.")
    
    if st.button("ğŸ”„ ReseteazÄƒ ConversaÈ›ia", type="primary"):
        clear_session_history(session_id)
        # GenerÄƒm un nou ID pentru a curÄƒÈ›a complet contextul
        new_id = str(uuid.uuid4())
        st.query_params["session_id"] = new_id
        st.rerun()

# --- LOGICA DE CHAT ---
st.title("ğŸ¨ Consultant TradiÈ›ii & Handmade")
st.markdown("ÃncarcÄƒ o pozÄƒ cu creaÈ›ia ta È™i hai sÄƒ Ã®i scriem povestea!")

# ÃncÄƒrcÄƒm istoricul din baza de date Ã®n UI
history_data = get_history(session_id)

for role, content, has_image in history_data:
    with st.chat_message(role):
        st.markdown(content)
        if has_image and role == "user":
            st.caption("*(Imagine analizatÄƒ anterior)*")

# Zona de input pentru fiÈ™iere
uploaded_file = st.file_uploader("ÃncarcÄƒ o pozÄƒ (JPEG/PNG) sau PDF", type=["jpg", "jpeg", "png", "pdf"])
image_data = None

if uploaded_file:
    # AfiÈ™Äƒm imaginea/fiÈ™ierul
    try:
        if uploaded_file.type in ["image/jpeg", "image/png"]:
            image = Image.open(uploaded_file)
            st.image(image, caption="Produsul tÄƒu", use_column_width=True)
            image_data = image
        else:
            st.info("FiÈ™ier PDF Ã®ncÄƒrcat. AI-ul Ã®l va analiza.")
            # Pentru PDF e nevoie de procesare specialÄƒ, dar Gemini acceptÄƒ bytes
            # Aici simplificÄƒm tratÃ¢nd imaginile ca prioritate vizualÄƒ
    except Exception as e:
        st.error(f"Eroare la Ã®ncÄƒrcare: {e}")

# Zona de input text
if prompt := st.chat_input("Despre ce produs vorbim azi?"):
    # 1. AfiÈ™Äƒm mesajul utilizatorului
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # 2. SalvÄƒm mesajul utilizatorului Ã®n DB
    save_message(session_id, "user", prompt, has_image=(uploaded_file is not None))

    # 3. PregÄƒtim apelul cÄƒtre Gemini
    inputs = [SYSTEM_PROMPT] # Ãncepem cu instrucÈ›iunile
    
    # AdÄƒugÄƒm istoricul recent pentru context (ultimele 10 mesaje pentru a nu depÄƒÈ™i tokenii rapid)
    for role, content, _ in history_data[-10:]:
        role_gemini = "user" if role == "user" else "model"
        inputs.append(f"{role_gemini}: {content}")
    
    # AdÄƒugÄƒm inputul curent
    inputs.append(f"user: {prompt}")

    # DacÄƒ avem imagine, o adÄƒugÄƒm la request
    if image_data:
        inputs.append(image_data)
        inputs.append("AnalizeazÄƒ aceastÄƒ imagine Ã®n contextul cerinÈ›ei.")

    # 4. GenerÄƒm rÄƒspunsul
    with st.chat_message("assistant"):
        with st.spinner("MeÈ™terul AI gÃ¢ndeÈ™te..."):
            try:
                response = model.generate_content(inputs)
                ai_text = response.text
                st.markdown(ai_text)
                
                # 5. SalvÄƒm rÄƒspunsul AI Ã®n DB
                save_message(session_id, "assistant", ai_text)
                
            except Exception as e:
                st.error(f"A apÄƒrut o eroare de conexiune cu Google: {e}")
